{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<font size=\"5\">\n",
    "\n",
    "Laboratorium z przedmiotu: \\\n",
    "**Głębokie uczenie i analiza obrazów**\n",
    "\n",
    "Ćwiczenie 3: \\\n",
    "**Konwolucyjne sieci neuronowe**\n",
    "\n",
    "</font>\n",
    "\n",
    "\\\n",
    "Marta Szarmach \\\n",
    "Zakład Telekomunikacji Morskiej \\\n",
    "Wydział Elektryczny \\\n",
    "Uniwersytet Morski w Gdyni\n",
    "\n",
    "09.2023\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "# 1. Wprowadzenie\n",
    "\n",
    "**Konwolucyjne sieci neuronowe** (ang. *convolutional neural networks*, CNN) to sieci, których działanie opiera się na konwolucji. W skrócie, sygnał dostarczony do sieci neuronowej (np. zdjęcie) analizowany jest fragment po fragmencie poprzez wykonanie konwolucji (wymnożenia i zsumowania) tegoż fragmentu z pewnym **filtrem** (ang. *kernel*). Zadaniem filtra jest (poprzez konwolucję) rozpoznanie w analizowanym sygnale pewnych cech (np. krawędzi), a na późniejszych etapie nawet pewnych obiektów. To właśnie na zawartość filtra składają się parametry sieci konwolucyjnej, wyznaczane w ramach jej treningu. \n",
    "\n",
    "Z racji swojej budowy i działania, konwolucyjne sieci neuronowe znalazły szerokie zastosowanie w analizie obrazów. Obrazy są najczęściej przedstawiane w formie 3-kanałowych macierzy (RGB), a następnie poddawane są konwolucji z filtrami, na którą wzór można zapisać tak:\n",
    "\\begin{equation*}\n",
    "    (A * H)[m,n] = \\sum_j \\sum_k H[j,k] \\cdot A[m-j,n-k]\n",
    "\\end{equation*}\n",
    "Każdy filtr ma za zadanie wykryć pewną konkretną cechę/zawartość analizowanego fragmentu obrazu. Zaczyna się zazwyczaj od odnajdywania prostych elementów, takich, jak krawędzie, a następnie, na kolejnych warstwach, sieć jest w stanie wykrywać coraz bardziej złożone kształty i obiekty. Zazwyczaj z każdą kolejną warstwą konwolucyjną zmniejsza się szerokość i wysokość obrazka, a zwiększa się ilość kanałów sygnału (tj. wykrywa się więcej kształtów - każdy kanał filtra odpowiada za odnajdywanie innych rodzajów kształtów, a tensor otrzymywany na wyjściu warstwy konwolucyjnej ma tyle kanałów, ile filtr na tej warstwie).\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Argenni/GUiAO_lab/main/rys/04_cnn.png'/>\n",
    "\n",
    "<font size=\"1\">Grafika: developersbreach.com</font>\n",
    "</div>\n",
    "\n",
    "Typowa budowa sieci konwolucyjnej przedstawiona jest na powyższym rysunku. Zazwyczaj sieci te buduje się z kilku występującycj po sobie bloków, złożonych z warstwy konwolucyjnej (wykonującej właściwą konwolucję), warstwy aktywacyjnej (np. ReLU) oraz innych, takich jak *dropout* czy *BatchNorm*. Na końcu sieci znajduje się najczęściej warstwa Flatten, która sprowadza dane dlań wejściowe do postaci 1-wymiarowego tensora, a za nią dane te przekształcane są przez jedną bądź kilka warstw liniowych. Na końcu sieci występuje warstwa przeprowadzająca ostateczną predykcję - w zależności od rozwiązywanego problemu, może to być Sigmoid, Softmax, itp.\n",
    "\n",
    "Pomiędzy blokami konwolucyjnymi możemy użyć także dodatkowej warstwy, zwanej *pooling layer*, która ma na celu zmiejszenie wymiaru ,,obrazu'' przekazywanego do następnej warstwy. Mamy fo wyboru:\n",
    "* *max pooling* - grupa pikseli zastępowana jest jednym, o wartości największej z grupy,\n",
    "* *average pooling* - grupa pikseli zastępowana jest jednym, o wartości średniej całej grupy.\n",
    "\n",
    "Hiperparametrami regulującymi działanie konwolucyjnych sieci neuronowych, które nie występowały w ,,zwykłych'' sieciach neuronowych (opartych na warstwach liniowych), są:\n",
    "* *kernel_size* - wielkość filtra,\n",
    "* *padding* - określa, jak „szeroka” ma być dodana (na dowolnej warstwie) do obrazu ramka z zer, co ma przeciwdziałać nadmiernemu zmiejszaniu się wymiarów obrazu wraz z kolejnymi konwolucjami, a także umożliwić dokładniejszą analizę brzegów obrazu,\n",
    "* *stride* - określa, za ile pikseli filtr wykona następną konwolucję.\n",
    "\n",
    "\n",
    "\n",
    "# 2. Cel ćwiczenia\n",
    "\n",
    "**Celem niniejszego ćwiczenia** jest zapoznanie się z budową i działaniem konwolucyjnych sieci neuronowych poprzez:\n",
    "* implementacji architektury pewnej konwolucyjnej sieci neuronowej o niewielkiej ilości warstw z wykorzystaniem biblioteki PyTorch i języka programowania Python,\n",
    "* skorzystanie z implementacji gotowej sieci konwolucyjnej, realizującej klasyfikację obrazów - AlexNet.\n",
    "\n",
    "\n",
    "# 3. Stanowisko laboratoryjne\n",
    "\n",
    "Do wykonania niniejszego ćwiczenia niezbędne jest stanowisko laboratoryjne, składające się z komputera klasy PC z zainstalowanym oprogramowaniem:\n",
    "* językiem programowania Python (w wersji 3.8),\n",
    "* IDE obsługującym pliki Jupyter Notebook (np. Visual Studio Code z rozszerzeniem ipykernel).\n",
    "\n",
    "\n",
    "# 4. Przebieg ćwiczenia\n",
    "## 4.1. Implementacja konwolucyjnej sieci neuronowej z wykorzystaniem biblioteki PyTorch\n",
    "\n",
    "Na początku wykonaj poniższy fragment kodu, aby zaimportować biblioteki niezbędne do wykonania poniższego ćwiczenia:\n",
    "* **PyTorch** - biblioteka wspomagająca budowanie architektur sieci neuronowych, posiadająca wbudowane moduły odpowiadające różnym warstwom sieci neuronowych, automatyczne obliczanie gradientów (*autograd*) niezbędne do przeprowadzenia treningu sieci neuronowych,\n",
    "* **NumPy** - biblioteka umożliwiająca wykonywanie wysoko zoptymalizowanych obliczeń matematycznych na objektach typu *numpy array* (wielowymiarowych tablic),\n",
    "* **Matplotlib** - biblioteka wspomagająca wizualizację pracy czy analizę danych poprzez wyświetlanie wykresów,\n",
    "* **Scikit-learn** - biblioteka zawierająca gotowe implementacje wielu algorytmów klasycznego uczenia maszynowego, a także zbiory danych czy metryki; tutaj skorzystamy ze zbioru danych `digits` (uproszczonej wersji zbioru MNIST) - `datasets.load_digits` oraz metody `model_selection.train_test_split` służącej do podziału danych na zestaw treningowy i testowy,\n",
    "* **Optuna** - biblioteka zawierająca narzędzia automatyzujące optymalizację danej funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install torch==2.0.1\n",
    "! python -m pip install numpy==1.22.3\n",
    "! python -m pip install scikit-learn==0.24.2\n",
    "! python -m pip install matplotlib==3.4.2\n",
    "! python -m pip install optuna\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# (dla zachowania powtarzalności wyników)\n",
    "np.random.seed(10) \n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie i przygotowanie danych\n",
    "\n",
    "Na początku przygotujmy dane, na których będziemy dziś pracować. Tym razem korzystać będziemy ze zbioru `digits`, zawierającego *num_samples* = 1797 obrazków o rozmiarze 8x8, przedstawiających odręcznie pisane cyfry. Uruchom kod z poniższej komórki, aby:\n",
    "* wczytać oryginalne dane (`digits`) do zmiennej $X$ i ich etykiety do zmiennej $y$,\n",
    "* obliczyć (z wykorzystaniem metody `numpy.unique`) w automatyczny sposób ilość klas występujących w naszym zbiorze danych (tj. ilość unikalnych wartości w etykietach) - wiemy, że powinno ich być 10, tyle, ile cyfr,\n",
    "* z pomocą `train_test_split` wydzielić 70% obrazków jako zestaw treningowy $Xtrain$, a pozostałą część danych po równo podzielić na zestaw walidacyjny $Xval$ i testowy $Xtest$ (po 15%),\n",
    "* przygotować etykiety tak, aby współpracowały z funkcją kosztu `CrossEntropyLoss`, którą zastosujemy przy treningu naszej sieci - odpowiedź od każdego neuronu zbierana będzie w osobnej kolumnie tablicy, dlatego nasze etykiety w formacie (*num_samples*,), zawierające wartości 0,1,...9 przekształcimy za pomocą one-hot-encodingu do postaci (*num_samples*, *num_classes*), np. 2 -> [0,0,1]\n",
    "* ostatecznie, dane i przekształcone etykiety, które będą przekazywane sieci neuronowej, przekształcić do formatu `torch.tensor`, aby były zrozumiałe dla PyTorcha; jednocześnie wyodrębniając w danych jako drugi wymiar ilość kanałów (w tym przypadku jest to 1): nasze dane wejściowe mają teraz kształt (*num_samples*, *num_channels*, *sample_size*, *sample_size*), gdzie *num_channels* = 1 (dla obrazów RGB byłoby to 3), *sample_size*=8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Inicjalizacja ----------------------------\n",
    "# Wczytanie danych\n",
    "digits = load_digits()\n",
    "X = digits.images\n",
    "y = digits.target\n",
    "num_classes = (np.unique(y)).shape[0]\n",
    "# Podziel dane na zestaw treningowy (70%), walidacyjny (15%) i testowy (15%) z wykorzystaniem metody train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,train_size=0.6)\n",
    "Xval, Xtest, yval, ytest = train_test_split(Xtest,ytest,train_size=0.5)\n",
    "# Dokonaj one-hot-encodingu etykiet z zestawu treningowego i walidacyjnego\n",
    "ytrain_ohe = np.identity(num_classes)[ytrain]\n",
    "yval_ohe = np.identity(num_classes)[yval]\n",
    "# Przekonwertuj dane wejściowe na tensory, by mogłby być obsługiwane przez PyTorch\n",
    "# i jednocześnie wydziel wymiar 1 jako ilość kanałów\n",
    "Xtrain = torch.tensor(Xtrain.reshape(-1, 1, Xtrain.shape[1], Xtrain.shape[2]))\n",
    "ytrain_ohe = torch.tensor(ytrain_ohe) \n",
    "Xval = torch.tensor(Xval.reshape(-1, 1, Xval.shape[1], Xval.shape[2])) \n",
    "yval_ohe = torch.tensor(yval_ohe)\n",
    "Xtest = torch.tensor(Xtest.reshape(-1, 1, Xtest.shape[1], Xtest.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Określenie struktury naszej sieci neuronowej\n",
    "\n",
    "W kolejnym kroku zdefiniujemy strukturę naszej konwolucyjnej  sieci neuronowej, korzystając z klas dostępnych w bibliotece PyTorch! Tak samo, jak ostatnio, zrobimy to w naszej własnej klasie - nazwijmy ją `ConvNet` - która musi dziedziczyć z klasy `torch.nn.Module`, w której umieścimy dwie metody:\n",
    "* metodę-konstruktor `__init__()` - opisującą budowę sieci; skorzystamy tu ze znanych już wcześniej warstw `torch.nn.Linear`, `torch.nn.ReLU`, `torch.nn.Dropout`, `torch.nn.Softmax` czy `torch.nn.Sequential`, ale użyjemy także kilku nowych, charakterystycznych dla konwolucyjnych sieci neuronowych:\n",
    "    * `torch.nn.Conv2d` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)) - realizująca właściwą konwolucję pomiędzy filtrami a fragmentami obrazów; wymaga takich argumentów, jak: ilość kanałów wejściowych/wyjściowych, wielkość filtra, *padding*, *stride*,\n",
    "    * `torch.nn.BatchNorm` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)) i ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)) - realizująca normalizację wsadową, zarówno na obrazach (2d), jak i na 1-wymiarowych tensorach (1d),\n",
    "    * `torch.nn.Flatten` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)) - realizująca ,,wypłaszczenie'' wejściowego sygnału 2d do postaci 1-wymiarowego tensora.\n",
    "* metodę `forward()` - w której określamy przepływ danych pomiędzy warstwami.\n",
    "\n",
    "Uzupełnij zatem poniższy kod! Oto założenia:\n",
    "* Niech nasza sieć neuronowa składa się z następujących warstw:\n",
    "\n",
    "2 x (`Conv2d` -> `BatchNorm2d` -> `Dropout` -> `ReLU`) -> `Flatten` -> `Linear` -> `BatchNorm1d` -> `Dropout` -> `Softmax`.\n",
    "* Podczas pierwszej konwolucji, niech wyznaczonych zostanie 16 kanałów, a po drugiej - 32 (ilość kanałów przechowywana jest w tablicy `num_conv_channels`).\n",
    "* Prawdopodobieństwo odrzucenia neuronu przez `dropout` niech wynosi 0,25.\n",
    "\n",
    "<font size=\"2\">Wskazówki:\n",
    "* Po każdej konwolucji, wymiary obrazu (szerokość i długość) zmieniają się zgodnie z poniższym wzorem:\n",
    "\\begin{equation*}\n",
    "    sample\\_size_{\\textrm{new}} = \\frac{sample\\_size_{\\textrm{original}} + 2 \\cdot padding - kernel\\_size}{stride} + 1 \n",
    "\\end{equation*}\n",
    "* Zastanów się, jak długi tensor zwróci nam warstwa `Flatten` (będzie Ci to potrzebne do właściwej inicjalizacji warstwy `Linear`) - do policzenia tego, na pewno będziesz potrzebować wymiaru obrazka po ostatniej konwolucji, a także ilości kanałów po tejże konwolucji!\n",
    "* `BatchNorm2d` jako argument  `num_features` wymaga ilości kanałów w analizowanych przezeń danych, natomiast `BatchNorm1d` - ilość neuronów z ostatniej warstwy `Linear`.\n",
    "* Wszystkie niezbędne dane przekazywać będziemy konstruktorowi jako argumenty.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Model konwolucyjnej sieci neuronowej:\n",
    "    (Conv -> BatchNorm -> Dropout -> ReLU) -> (Conv -> BatchNorm -> Dropout -> ReLU) -> (Flatten -> Linear -> BatchNorm -> Dropout -> Softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, sample_size, output_layer_size, kernel_size, padding, stride):\n",
    "        \"\"\"\n",
    "        Definiuje budowę sieci. Argumenty: \\n\n",
    "        - input_channels - ilość kanałów w wejściowych obrazkach (skalar, int), \\n\n",
    "        - sample_size - długość/szerokość wejściowego obrazka (skalar, int), \\n\n",
    "        - output_layer_size - ilość neuronów na ostatniej warstwie (skalar, int), \\n\n",
    "        - kernel_size - wielkość filtra do konwolucji (skalar, int), \\n\n",
    "        - padding - ,,grubość'' ramki z zer dodowananej do obrazka (skalar, int), \\n\n",
    "        - stride - co ile pikseli obrazka wykonywana jest konwolucja (skalar, int).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        num_conv_channels = [16, 32] # Do dowolnej modyfikacji - ilość kanałów po kolejnych konwolucjach\n",
    "        # ---------------------- UZUPEŁNIJ KOD -----------------------------------\n",
    "        # Oblicz rozmiary obrazków po pierwszej konwolucji\n",
    "        size1 = 0\n",
    "        # Oblicz rozmiary obrazków po drugiej konwolucji\n",
    "        size2 = 0\n",
    "        # Zacznij definiować budowę sieci:\n",
    "        self.first_layer = torch.nn.Sequential(\n",
    "            # Warstwa konwolucyjna\n",
    "            \n",
    "            # BatchNorm2d\n",
    "            \n",
    "            # Dropout (niech neuron zostanie usunięty z prawdopodobieństwem 0.25)\n",
    "            \n",
    "            # Funkcja aktywacji ReLU\n",
    "             \n",
    "            )\n",
    "        self.second_layer = torch.nn.Sequential(\n",
    "            # Warstwa konwolucyjna\n",
    "            \n",
    "            # BatchNorm2d\n",
    "            \n",
    "            # Dropout (niech neuron zostanie usunięty z prawdopodobieństwem 0.25)\n",
    "            \n",
    "            # Funkcja aktywacji ReLU\n",
    "            \n",
    "            )\n",
    "        self.third_layer = torch.nn.Sequential(\n",
    "            # Flatten\n",
    "            \n",
    "            # Linear\n",
    "            \n",
    "            # BatchNorm1d\n",
    "            \n",
    "            # Dropout\n",
    "            \n",
    "            # Softmax\n",
    "           \n",
    "        )\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(self, X):\n",
    "            \"\"\" \n",
    "            Definiuje przepływ danych w sieci. \\n\n",
    "            Argument: X - dane wejściowe, obrazki w postaci torch.tensor, shape=(num_samples, input_channels, sample_size, sample_size). \\n\n",
    "            Zwraca: X - odpowiedź sieci w postaci prawdopodobieństw, torch.tensor, shape=(sum_samples, num_classes).\n",
    "            \"\"\"\n",
    "            # ------------------- UZUPEŁNIJ KOD ----------------\n",
    "            X = 0\n",
    "            # --------------------------------------------------\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujmy utworzyć obiekt stworzonej przez nas klasy ConvNet i wykonać jakiś próbny *forward pass* na danych walidacyjnych, aby przekonać się, czy budowa naszej sieci jest poprawna (przynajmniej pod kątem składnowym i numerycznym, tj. czy zgadzają się wymiary tensorów przekazywanych pomiędzy warstwami). Uruchom więc kod z poniższej komórki. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvNet(\n",
    "    input_channels=1,\n",
    "    sample_size=Xval.shape[2],\n",
    "    output_layer_size=num_classes,\n",
    "    kernel_size=3,\n",
    "    padding=0,\n",
    "    stride=1)\n",
    "cnn = cnn.double()\n",
    "pred = cnn(Xval)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych: \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbieramy odpowiedzi od każdego wyjściowego neuronu, a każda oznacza prawdopodobieństwo przynależności badanego obrazka do odpowiedniej klasy. Pamiętaj, że nie ma po co przywiązywać się do predykcji otrzymanych na tym etapie - sieć jeszcze nie została niczego nauczona! \n",
    "\n",
    "\n",
    "### Trening sieci neuronowej\n",
    "\n",
    "Napiszmy w takim razie funkcję `train_cnn()`, w której przeprowadzimy trening naszej konwolucyjnej sieci neuronowej. Podobnie, jak poprzednio, wykorzystajmy algorytm optymalizacji Adam (który, jak pamiętamy, potrzebuje odniesienia do parametrów, które ma optymalizować (argument `params` - przekażmy wynik metody `parameters()` na obiekcie naszej klasy ConvNet), stałej uczenia $\\alpha$ (argument `lr` - przekażmy na stałe wartość 0,005), a także stałej regularyzacji $\\lambda$ (argument `weight_decay` - przekażmy na stałe wartość 0,001), a jako funkcję kosztu wykorzystajmy CrossEntropyLoss.\n",
    "\n",
    "Niech zawartość naszej funkcji będzie podobna, jak na poprzednim ćwiczeniu:\n",
    "* Utwórz obiekt klasy ConvNet, a także obiekt zawierający odniesienie do właściwego algorytmu optymalizacji i funkcji kosztu.\n",
    "* Powtarzaj iteracyjnie:\n",
    "    * Przełącz sieć na tryb walidacji, wykonaj *forward pass* na danych walidacyjnych, oblicz wartość kosztu na tych danych i zapisz ją w odpowiedniej zmiennej (pamiętaj o odłączeniu ,,niepotrzebnych'' dla PyTorcha zmiennych metodą `detach()`).\n",
    "    * Przełącz sieć na tryb treningu, wykonaj *forward pass* na danych treningowych, oblicz wartość kosztu na tych danych i zapisz ją w odpowiedniej zmiennej, dokonaj propagacji wstecznej błędu, wykonaj jedną iterację algorytmu optymalizacji, po czym usuń z pamięci obliczone gradienty.\n",
    "    \n",
    "Wyświetlenie zmian kosztu wraz z kolejnymi iteracjami zostało już dla Ciebie napisane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(Xtrain, ytrain, Xval, yval, num_classes, kernel_size=3, padding=0, stride=1, lambdA=0.001, if_plot=True):\n",
    "    \"\"\"\n",
    "    Wykonaj trening swojej sieci neuronowej zdefiniowanej w klasie NeuralNet \n",
    "    na zadanych danych wejściowych i z określoną stałą regularyzacji lambdA. \\n\n",
    "    Argumenty: \\n\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, input_channels, sample_size, sample_size) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane testowe (torch tensor, shape = (num_samples * percentage_val, input_channels, sample_size, sample_size) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar), \\n\n",
    "    - kernel_size - wielkość filtra użytego do konwolucji (int, skalar) (opcjonalnie, domyślnie 3), \\n\n",
    "    - padding - wielkość ,,ramki'' dodawanej do danych przed konwolucją (int, skalar) (opcjonalnie, domyślnie 0), \\n\n",
    "    - stride - co ile pikseli ma być robiona konwolucja (int, skalar) (opcjonalnie, domyślnie 1), \\n\n",
    "    - lambdA - stała regularyzacji (float, skalar) (opcjonalnie, domyślnie 0.001), \\n\n",
    "    - if_plot - Boolean, decyduje, czy po treningu wyświetlić krzywe uczenia (opcjonalnie, domyślnie True). \\n\n",
    "    Zwraca: cnn - wytrenowana sieć neuronowa, zdefiniowana w klasie ConvNet.\n",
    "    \"\"\"\n",
    "    cnn = ConvNet( \n",
    "        input_channels = Xtrain.shape[1], \n",
    "        sample_size = Xtrain.shape[2],\n",
    "        output_layer_size=num_classes,\n",
    "        kernel_size=kernel_size, \n",
    "        padding=padding, \n",
    "        stride=stride\n",
    "        ) \n",
    "    cnn = cnn.double() \n",
    "    loss_train_vec = [] \n",
    "    loss_val_vec = []  \n",
    "    # ---------------------------- UZUPEŁNIJ KOD ---------------------------------------\n",
    "    # Utwórz obiekt związany z funkcją kosztu - CrossEntropyLoss\n",
    "    criterion = 0\n",
    "    # Utwórz obiekt związany z metodą optymalizacji - Adam\n",
    "    optimizer = 0  \n",
    "    for i in range(1000):\n",
    "        if if_plot:\n",
    "            # Przełącz sieć w tryb walidacji\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                # Wykonaj forward pass na danych walidacyjnych\n",
    "                pred = 0\n",
    "                # Oblicz koszt na tych danych\n",
    "                loss_val = 0 \n",
    "                # Zapisz koszt w odpowiedniej zmiennej (loss_val_vec)\n",
    "                \n",
    "        # Przełącz sieć w tryb treningu\n",
    "        \n",
    "        # Wykonaj forward pass na danych treningowych\n",
    "        pred = 0\n",
    "        # Oblicz koszt na tych danych\n",
    "        loss_train = 0\n",
    "        # Wykonaj propagację wsteczną kosztu\n",
    "        \n",
    "        # Wykonaj 1 iterację algorytmu optymalizacji\n",
    "        \n",
    "        # Wyzeruj gradienty\n",
    "        \n",
    "        # Zapisz koszt do odpowiedniej zmiennej (loss_train_vec)\n",
    "        \n",
    "    # ------------------------------------------------------------------------\n",
    "    if if_plot:\n",
    "        print(\"  Zakończono trening sieci.\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_train_vec, color='k')\n",
    "        ax.plot(loss_val_vec, color='r')\n",
    "        ax.set_title(\"Krzywe uczenia\")\n",
    "        ax.set_xlabel(\"Iteracja\")\n",
    "        ax.set_ylabel(\"Koszt\")\n",
    "        ax.legend([\"Koszt na danych treningowych\", \"Koszt na danych walidacyjnych\"])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, jak zmieniły się predykcje dokonane przez naszą sieć, kiedy czegoś ją nauczyliśmy: powinniśmy widzieć większe zróżnicowanie wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = train_cnn(\n",
    "    Xtrain=Xtrain, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    if_plot=False)\n",
    "pred = nn(Xval)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych (po treningu): \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja\n",
    "\n",
    "Kolejnym krokiem jest napisanie funkcji, która analizuje prawdopodobieństwa zwracane przez sieć neuronową i zwraca konkretne numery klas, do których powinny należeć analizowane obrazki - przypomnijmy, że z pomocą `torch.argmax()` należy znaleźć indeks klasy, której sieć przyporządkowała najwyższe prawdopodobieństwo. Uzupełnij więc kod funkcji `pred_cnn()`, która wykona taką operację. <font size=\"2\">Nie zapominaj o argumencie `dim`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cnn(X, cnn):\n",
    "    \"\"\"\n",
    "    Dokonuje ostatecznej predykcji sieci neuronowej (obiektu NeuralNet) - wskazania klasy - dla danych wejściowych X. \\n\n",
    "    Argumenty: \\n\n",
    "    - X - dane wejściowe (torch tensor, shape = (num_samples, num_features) ), \\n\n",
    "    - nn - model sieci neuronowej, obiekt naszej klasy NeuralNet. \\n\n",
    "    Zwraca: pred - numer klasy wg klasyfikatora właściwy dla X (numpy array, shape = (num_samples,) ).\n",
    "    \"\"\"\n",
    "    # --------- UZUPEŁNIJ KOD -------------\n",
    "    pred = 0\n",
    "    # -------------------------------------\n",
    "    return pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy, jak wyglądają nasze predykcje dla danych walidacyjnych, kiedy jednoznacznie wskazujemy, do której klasy przypisać daną próbkę (a nie operujemy na prawdopodobieństwach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_cnn(Xval, cnn)\n",
    "print(\"Przykładowe predykcje dla danych walidacyjnych: \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dobór hiperparametrów z wykorzystaniem biblioteki Optuna\n",
    "\n",
    "Przy budowi sieci konwolucyjnych mamy do czynienia z dużą ilością hiperparametrów - wystarczy przypomnieć *kernel_size*, *padding* czy *stride*. Znalezienie idealnego zestawu hiperparametrów ręcznie (tak, jak robiliśmy to podczas poprzedniego ćwiczenia) może być problematyczne. Użyjemy zatem biblioteki o nazwie Optuna, która pomaga nam w optymalizacji wielu hiperparametrów naraz.\n",
    "\n",
    "Zgodnie z tutorialem [TUTAJ](https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/002_multi_objective.html), musimy najpierw napisać funkcję `objective`, która ma określać to, co chcemy optymalizować --- musi wiedzieć, jakie parametry ma dostosowywać, a także znać miarę, według której można ocenić, czy ,,zbliżamy się'' do celu czy też nie. W naszym przypadku, poszukujemy takiego zestawu hiperparametrów *kernel_size*, *padding* czy *stride*, przy których nasza sieć osiąga możliwie najwyższą dokładność na danych walidacyjnych.\n",
    "\n",
    "Uzupełniony kod funkcji `objective` powinien zawierać więc następujące elementy:\n",
    "* Utworzenie obiektów `trial.suggest_int`, definiujących zakres wartości różnych hiperparametrów, które chcemy przebadać (w naszym przypadku, wszystkie szukane wartości są liczbami całkowitymi).\n",
    "* Przeprowadze *forward pass* na danych walidacyjnych:\n",
    "    * utworzenie obiektu klasy ConvNet i wytrenowanie sieci z pewnym (wybranym przez Optunę) zestawem hiperparametrów,\n",
    "    * dokonanie predykcji (funkcja `pred_cnn`) na danych walidacyjnych,\n",
    "* Obliczenie i zwrócenie dokładności predykcji (przypomnij sobie z poprzednich ćwiczeń trick z `np.where`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, Xtrain, ytrain, Xval, yval, num_classes): \n",
    "    \"\"\"\n",
    "    Funkcja określająca, co ma być optymalizowane przez Optunę. \\n\n",
    "    Argumenty: \\n\n",
    "    - trial - wewnętrzny argument Optuny, \\n\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, input_channels, sample_size, sample_size) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane testowe (torch tensor, shape = (num_samples * percentage_val, input_channels, sample_size, sample_size) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar). \\n\n",
    "    Zwraca: accuracy - dokładność sieci na danych walidacyjnych przy badanych hiperparametrach (skalar, float).\n",
    "    \"\"\"\n",
    "    # ------------------------- UZUPEŁNIJ KOD ------------------------------\n",
    "    # Określ wartości hiperparametru kernel_size, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    kernel_sizes = trial.suggest_int(\"kernel_size\", 1, 3, log=False)\n",
    "    # Określ wartości hiperparametru padding, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    paddings = 0\n",
    "    # Określ wartości hiperparametru stride, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    strides = 0\n",
    "    # Wytrenuj sieć klasy ConvNet z badanymi hiperparametrami\n",
    "    cnn = 0\n",
    "    # Dokonaj predykcji na danych walidacyjnych\n",
    "    pred = 0\n",
    "    # Oblicz dokładność klasyfikacji\n",
    "    accuracy = 0\n",
    "    # -----------------------------------------------------------------------\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym krokiem, po napisaniu funkcji `objective`, jest utworzenie obiektu `study`, który będzie przechowywał wyniki testowania różnych kombinacji wartości hiperparametrów (i dzięki któremu wybierzemy ten optymalny zestaw).\n",
    "* Korzystając z metody `optuna.create_study` (i wskazując w argumencie `direction`, że chcemy maksymalizować optymalizowaną funkcję), utwórz obiekt o nazwie `study`.\n",
    "* Wywołaj na tym obiekcie metodę `optimize` - musisz jej przekazać zdefiniowany wcześniej `objective`, wówczas `study` będzie wiedzieć, co ma optymalizować i w jaki sposób. UWAGA! Musisz zastosować pewien trick opisany [TUTAJ](https://optuna.readthedocs.io/en/stable/faq.html#how-to-define-objective-functions-that-have-own-arguments), aby do funkcji `objective` przekazać własne argumenty $Xtrain$, $ytrain$, $Xval$, $yval$  oraz *num_classes* - proponuję zastosować podejście z lambdą. Jako argument musisz też przekazać ilość prób (losowań zestawu hiperparametrów), które podejmie Optuna (argument `n_trials`) - proponuję w ramach ćwiczeń podać wartość 5, aby czas obliczeń nie był znacząco wydłużony, natomiast w rzeczywistych projektach radzę używać wyższych wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Dobór hiperparametrów ------------------------\n",
    "# ---------------------------- UZUPEŁNIJ KOD ----------------------------\n",
    "# Utwórz obiekt o nazwie study (użyj optuna.create_study, nie zapominaj o argumencie direction)\n",
    "study = 0\n",
    "# Optymalizuj hiperparametry kernel_size, padding i stride - wykonaj optimize() na obiektcie study\n",
    "# (funkcję objective przekaż w postaci wyrażenia lambda)\n",
    "\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli optymalizacja przebiegła pomyślnie, zobaczmy, jaki zestaw hiperparametrów okazał się najlepszy! Obiekt `study` przechowuje najlepsze wartości w słowniku `best_params` - wystarczy wyszukać po nazwie nadanej hiperparametrowi podczas tworzenia `objective`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetl rezultat optymalizacji\n",
    "print(\"Najwyższa dokładność podczas optymalizacji: \" + str(study.best_value))\n",
    "# ------------------------- UZUPEŁNIJ KOD -------------------------------\n",
    "optimal_kernel_size = 0\n",
    "print(\"Najlepszy kernel_size: \" + str(optimal_kernel_size))\n",
    "optimal_padding = 0\n",
    "print(\"Najlepszy padding: \" + str(optimal_padding))\n",
    "optimal_stride = 0\n",
    "print(\"Najlepszy stride: \" + str(optimal_stride))\n",
    "# -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając wybrane wartości hiperparametrów, czas uruchomić właściwy trening naszej konwolucyjnej sieci neuronowej! Uruchom po prostu poniższy kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Trening sieci --------------\n",
    "cnn = train_cnn(\n",
    "    Xtrain=Xtrain, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    kernel_size=optimal_kernel_size,\n",
    "    padding=optimal_padding,\n",
    "    stride=optimal_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak zwykle, sprawdź, czy na wykresie krzywych uczenia nie obserwujesz znaczącego *overfittingu* (czy krzywa dla zestawu walidacyjnego nie rośnie przy dalszym spadku krzywej dla zestawu treningowego). Jeśli wszystko jest w porządku, sprawdźmy dokładność naszego modelu także na danych testowych z zestawu `digits`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Predykcja i sprawdzenie działania -------------------\n",
    "pred = pred_cnn(Xtrain, cnn)\n",
    "accuracy = np.mean(pred==ytrain)\n",
    "print(\"Dokładność modelu na danych treningowych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_cnn(Xval, cnn)\n",
    "accuracy = np.mean(pred==yval)\n",
    "print(\"Dokładność modelu na danych walidacyjnych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_cnn(Xtest, cnn)\n",
    "accuracy = np.mean(pred==ytest)\n",
    "print(\"Dokładność modelu na danych testowych: \"+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Wykorzystanie gotowej architektury - AlexNet\n",
    "\n",
    "Badacze tematyką klasyfikacji obrazów zajmują się od lat. Istnieje wiele gotowych architektur konwolucyjnych sieci neuronowych, które zostały wykrenowane do oceny, co znajduje się na przekazany jej obrazku. Jedną z nich jest AlexNet, wytrenowana na dużym zbiorze zdjęć ImageNet, która rozróżnia 1000 klas obiektów na zdjęciach. AlexNet składa się z pięciu warstw konwolucyjnych, trzech wastw *max pooling*, oraz trzech wastw *fully-connected* (czyli liniowych) na końcu, wewnątrz używa funkcji aktywacji ReLU, a jedynie na warstwie wyjściowej - funkcji Softmax. Tak prezentuje się jej architektura:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Argenni/GUiAO_lab/main/rys/05_alexnet.png'/>\n",
    "\n",
    "<font size=\"1\">Grafika: hackmd.io / Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, 2012 </font>\n",
    "</div>\n",
    "\n",
    "Jej implementację (wraz z wagami) można pobrać z pomocą PyTorcha. Możemy ją zaimportować do naszego projektu, pobrać etykiety klas używanych przez ImageNet (z repozytorium twórców ImageNet), a następnie dokonać klasyfikacji dowolnego zdjęcia! Musimy jedynie pamiętać, aby odpowiednio zdjęcie przekształcić: musi ono mieć wymiary 3x224x224 (oczywiście jako zdjęcie RGB, stąd 3 kanały), a także być wstępnie znormalizowane. Poniższy fragment kodu, tworzony w oparciu o tutorial [TUTAJ](https://pytorch.org/hub/pytorch_vision_alexnet/) realizuje właśnie wspomniane wyżej zadania:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Klasyfikacja obrazów z AlexNet -----------------------------\n",
    "# Import niezbędnych bibliotek\n",
    "! python -m pip install torch==2.0.1\n",
    "! python -m pip install numpy==1.22.3\n",
    "! python -m pip install matplotlib==3.4.2\n",
    "! python -m pip install wget==3.2\n",
    "! python -m pip install PIL\n",
    "! python -m pip install torchvision==0.15.2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wget\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Importuj AlexNet - w pełni wytrenowany model\n",
    "alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "alexnet.eval()\n",
    "# Pobierz nazwy klas, jakie posiada ImageNet\n",
    "if not os.path.exists(\"utils/imagenet_classes.txt\"):\n",
    "    wget.download(\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", out=\"utils/imagenet_classes.txt\")\n",
    "with open(\"utils/imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "    \n",
    "# Importuj przykładowe zdjęcie psa\n",
    "if not os.path.exists(\"utils/dog.jpg\"): \n",
    "    wget.download(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", out=\"utils/dog.jpg\")\n",
    "# Przekształć zdjęcie, by AlexNet mógł je przetworzyć\n",
    "input_image = Image.open(\"utils/dog.jpg\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas na Ciebie! Dokonaj klasyfikacji pobranego zdjęcia za pomocą AlexNet. Wykonaj *forward pass* na zdjęciu zapisanym w zmiennej `input_batch`, wywołując `alexnet` jak każdy inny model PyTorcha, wyszukaj klasę z najwyżej ocenionym przez AlexNet prawdopodobieństwem (wykorzystaj znów `torch.argmax`) i w pobranym słowniku etykiet `categories` wyszukaj nazwę odpowiedniej klasy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ UZUPEŁNIJ KOD --------------------------------\n",
    "# Dokonaj klasyfikacji zdjęcia\n",
    "with torch.no_grad():\n",
    "    output = 0\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "pred_class = 0\n",
    "# Odczytaj nazwę klasy\n",
    "pred_category = 0\n",
    "# -----------------------------------------------------------------------------\n",
    "plt.imshow(input_image)\n",
    "print(\"\\nPredykcja: \" + pred_category + \" (\" + str(probabilities[pred_class].numpy()) + \" pewności)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz oczywiście samodzielnie poeksperymentować, podmieniając zdjęcia, których klasyfikacji ma dokonać AlexNet.\n",
    "\n",
    "\n",
    "## 5. Pytania kontrolne\n",
    "1. Opisz bardzo krótko, na czym polega zasada działania konwolucyjnych sieci neuronowych.\n",
    "2. Na co wpływa wartość hiperparametru: *kernel_size* / *padding* / *stride* ?\n",
    "3. Z jakich warstw zazwyczaj składa się konwolucyjna sieć neuronowa?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('vscode0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "778cfed3981b96449a29dc7b86e438e34449205630b92b8bee0fcf8135b84476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
